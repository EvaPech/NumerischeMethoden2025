{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "---\n---\n\n<h1><center><ins>Exercise Sheet 3</ins></center></h1>\n<h2><center>Numerical Methods <br><br>\n\n---\n---",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy import exp",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Matplotlib is building the font cache; this may take a moment.\n"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 1 - Root finding algorithms\n\n**(A)** Implement the *bisection*, *secant*, *false position* and *Newton-Raphson* root finding methods, by coding your own version of these algorithms. Make sure to test your codes, checking that indeed they are able to find the root of a function (to do this, you can for example pick an analytic function that allows you test the codes and for which you can compute the roots analytically).\n\n**(B)** Use your implementation of the 4 root finding methods (from part **A**) to compute the root of the function:\n\n$$f(x) = e^x - 1 - x - \\frac{x^2}{2}$$\n\nin the interval $x\\in[-1,2]$. For each method, print out the position of the root and the number of iterations needed to reach it.\n\n**(C)** Discuss your results, commenting how the methods compare to one another. Which one is the fastest/slowest? Why? What is the impact of the points you selected to start your iterations?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import math\n# Define function to test the different methods\n# f(x) = exp(x) - 10\n# Exact solution: x = ln(10) = 2.30258509...\n\ndef tf(x):\n    return np.exp(x)-10\n    \ndef dtf(x):\n    return np.exp(x)\n\n# Newton-Raphson-Method\n\ndef newton(f,f1,a,eps,N):\n    x=a\n    for i in range(N):\n        x_old=x\n        x=x-f(x)/df(x)\n        error=abs(x-x_old)\n        if error < eps:\n            break  \n    return x,i+1,error\n\n#Bisection-Method\n\ndef bisect(f,a,b,eps,N):\n    if f(a)*f(b)>0:\n        raise ValueError(\"No change of sign in intervall!\")\n\n    for i in range(N):\n        x_m=0.5*(a+b)\n        f_m=f(x_m)\n        error=abs(b-a)/2.0\n        if f_m == 0 or error<eps:\n                return x_m,i+1,error\n                break\n        if f(a)*f_m < 0:\n            b=x_m\n        else:\n            a=x_m\n    return x_m,N,error\n    \n\ndef secant(f,a,b,eps,N):\n    if f(a)*f(b)>0:\n        raise ValueError(\"No change of sign in intervall!\")\n\n    for i in range(N):\n        x_r= b - (f(b) /(f(b)-f(a)) )*(b-a)\n        a=b\n        b=x_r\n        error=abs(a-b)\n        if error<eps:\n                return x_r,i,error\n                break       \n    return x_r,N,error\n\ndef falsepos(f,a,b,eps,N):\n  \n    if f(a)*f(b)>0:\n        raise ValueError(\"No change of sign in intervall!\")\n        \n    x_r=(a+b)/2\n    for i in range(N):\n        x_alt=x_r\n        x_r= b - (f(b) /(f(b)-f(a)) )*(b-a)\n        if f(a)*f(x_r)<0:\n            b=x_r\n        else:\n            a=x_r\n        error=abs(x_alt-x_r)\n#        print(a,b,x_r,error)\n        if error<eps:\n                return x_r,i,error\n                break\n   \n    return x_r,N,error\n\n# Solve the test-equation with the 4 different methods\n# Set precision and maximum number of iterations\n\nprecision=1e-07\nmaxit=100\n\n#Newton with initial value: 1\nsol_newton,maxit_newton,err_newton=newton(tf,dtf,1,precision,maxit)\n\n#Bisection/Secant/Fales Position with starting interval [2,3]\nsol_bisect,maxit_bisect,err_bisect=bisect(tf, 2,3,precision,maxit)\nsol_secant,maxit_secant,err_secant=secant(tf, 2,3,precision,maxit)\nsol_falsepos,maxit_falsepos,err_falsepos=falsepos(tf, 2,3,precision,maxit)\n\nprint(\"Exact solution for test equation: x=ln(10)=\", np.log(10))\nprint(\"\")\nif maxit_newton == maxit:\n    print(\"Newton| Precision not reached with\",maxit,\"iterations\")\nelse:\n    print(\"Newton| root=\",sol_newton,\" Precision reached with\", maxit_newton, \"Iterations\")   \n    \nif maxit_bisect == maxit:\n     print(\"Bisection| Precision not reached with\",maxit,\"iterations\")\nelse:    \n    print(\"Bisection| root=\",sol_bisect,\" Precision reached with\", maxit_bisect, \"Iterations\")\n\nif maxit_secant == maxit:\n     print(\"Secant| Precision not reached with\",maxit,\"iterations\")\nelse:\n    print(\"Secant| root=\",sol_secant,\" Precision reached with\", maxit_secant, \"Iterations\")\n\nif maxit_falsepos == maxit:\n     print(\"False position| Precision not reached with\",maxit,\"iterations\")\nelse:    \n    print(\"False position| root=\",sol_falsepos,\" Precision reached with\", maxit_falsepos, \"Iterations\")\n\ndef f(x):\n    return np.exp(x) - 1.0 - x - 0.5*x*x\n\ndef df(x):\n    return np.exp(x) - 1.0 - x\n\ndef d2f(x):\n    return np.exp(x) - 1.0\n\n\nprint(\"\")\nprint(\"\")\n\n## \n#Solve equation from part B\n\nmaxit=10000\nprecision=1e-7\n\n#Newton with initial value: 1\nsol_newton,maxit_newton,err_newton=newton(f,df,1,precision,maxit)\n\n#Bisection/Secant/Fales Position with starting interval [-1,2]\nsol_bisect,maxit_bisect,err_bisect=bisect(f,-1,2,precision,maxit)\nsol_secant,maxit_secant,err_secant=secant(f,-1,2,precision,maxit)\nsol_falsepos,maxit_falsepos,err_falsepos=falsepos(f,-0.1,0.1,precision,maxit)\n\nprint(\"Solve equation from part B\\n\")\n\nif maxit_newton == maxit:\n    print(\"Newton| Precision not reached with\",maxit,\"iterations\")\nelse:\n    print(\"Newton| root=\",sol_newton,\" Precision reached with\", maxit_newton, \"Iterations\")   \n    \nif maxit_bisect == maxit:\n     print(\"Bisection| Precision not reached with\",maxit,\"iterations\")\nelse:    \n    print(\"Bisection| root=\",sol_bisect,\" Precision reached with\", maxit_bisect, \"Iterations\")\n\nif maxit_secant == maxit:\n     print(\"Secant| Precision not reached with\",maxit,\"iterations\")\nelse:\n    print(\"Secant| root=\",sol_secant,\" Precision reached with\", maxit_secant, \"Iterations\")\n\nif maxit_falsepos == maxit:\n     print(\"False position| Precision not reached with\",maxit,\"iterations\")\nelse:    \n    print(\"False position| root=\",sol_falsepos,\" Precision reached with\", maxit_falsepos, \"Iterations\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Exact solution for test equation: x=ln(10)= 2.302585092994046\n\nNewton| root= 2.3025851142114617  Precision reached with 32 Iterations\nBisection| root= 2.3025850653648376  Precision reached with 24 Iterations\nSecant| root= 2.3025850929942404  Precision reached with 5 Iterations\nFalse position| root= 2.302585070365059  Precision reached with 13 Iterations\n\n\nSolve equation from part B\n\nNewton| root= 7.029412567791687e-06  Precision reached with 186 Iterations\nBisection| root= 7.62939453125e-06  Precision reached with 17 Iterations\nSecant| root= 3.104439253236525e-06  Precision reached with 46 Iterations\nFalse position| root= -0.0010050017417785745  Precision reached with 4196 Iterations\n"
        }
      ],
      "execution_count": 154
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 1 - Discussion of results\n\nFor the equation of part (B), the fastest method is the secant method. False position does not reach the required precision in under 1000 iterations (in fact, it takes 44608 iterations). This method gets \"stuck\" with the lower border of 2, i.e., this initial value is never changed and thus many more iterations are needed to get the required results. Changing the borders closer to the expected value of 0 (e.g. [-0.1,0.1] reduces the number of iterations (to 4196 in that case), but the method is still slower than the others\n\n",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      }
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 2 - Sets of linear equations\n\nDetermine the solution to the following set of linear equations:\n\n$$ \n\\begin{cases}\n5 x_1 + 3 x_2 &= 15 \\\\\nx_1 - 4 x_2 &= -2 \\ ,\n\\end{cases}\n$$\n\nwhere $x_1$ and $x_2$ are the variables of interest.\n\n**(A)** Formulate the problem by using the matrix representation, as we saw in class, clearly defining the coefficient matrix and the vector of right-hand-side values.\n\n**(B)** Using the appropriate built-in python functions, carry out the LU decomposition of the coefficient matrix, and print out the L and U matrices separately. Solve the set of equations and check that the solution is indeed valid.\n\n**(C)** What is the solution to the following set of equations? \n\n$$ \n\\begin{cases}\nx_1 - 4 x_2 &= 3 \\\\\n5 x_1 + 3 x_2 &= -7\n\\end{cases}\n$$\n\nPrint out the solution, and motivate the steps you took to solve it.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 2A\n\nMatrix represantation of equations: A**x**=**b**\n\n\n\n$$ \nA= \\begin{pmatrix}\n5 & 3 \\\\\n1 & -4 \\\\\n\\end{pmatrix}\n$$\n\n$$\nb=\\begin{pmatrix}\n15 \\\\-2\n\\end{pmatrix}\n$$\n\nwith\n\n$$\nx=\\begin{pmatrix}\nx_1 \\\\x_2\n\\end{pmatrix}\n$$\n\n**Solution**\n\nEquation 1: \n\nsubtract 1/5 * equation 1 from equation 2:\n\n$$ \n\\begin{cases}\n5 x_1 + 3 x_2 &= 15 \\\\\n - \\frac{23}{5} x_2 &= -5 \\ \n\\end{cases}\n$$\n\nmultiply equation 2 by -5:\n\n$$ \n\\begin{cases}\n5 x_1 + 3 x_2 &= 15 \\\\\n23 x_2 &= 25 \\ \n\\end{cases}\n$$\n\ndivide equation 2 by 23:\n\n$$ \n\\begin{cases}\n5 x_1 + 3 x_2 &= 15 \\\\\n  x_2 &= \\frac{25}{23} \\ \n\\end{cases}\n$$\n\nsubtract 3 * equation 2 from equation 1:\n\n$$ \n\\begin{cases}\n5 x_1  &= \\frac{270}{23} \\\\\n  x_2 &= \\frac{25}{23} \\ \n\\end{cases}\n$$\n\ndivide equation 1 by 5:\n\n$$ \n\\begin{cases}\n  x_1  &= \\frac{54}{23} \\\\\n  x_2 &= \\frac{25}{23} \\ \n\\end{cases}\n$$\n\nThus:\n\n$$ \n\\begin{cases}\n  x_1  & \\approx 2.347826... \\\\\n  x_2 & \\approx 1.086956... \\ \n\\end{cases}\n$$\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from numpy.linalg import solve, det, norm, cond\nfrom scipy.linalg import lu, lu_factor, lu_solve\n\n#Define matrix A and vector b to represent the equation\n\nA = np.array([\n    [5.0, 3.0],\n    [1, -4]\n], dtype=float)\n\nb = np.array([15, -2.0], dtype=float)\n\n\n\n#Use the lu-function for the LU-Decomposition\nP,L,U = lu(A)\nprint (\"Exercise 2A\\n\")\nprint(\"lower triangular L:\\n\", L)\nprint(\"\\nupper triangular U:\\n\", U)\n\n#Use the lu_factor function to solve the equation with LU-Decomposition\nLU, piv = lu_factor(A)         \nx_lu = lu_solve((LU, piv), b) \nprint(\"\\nsolution for x (LU):\\n\", x_lu)\n\n#Use solve-function\nx_direct = solve(A, b)\nprint(\"\\ndirect solution for x (direkt):\\n\", x_direct)\n\nprint(\"\")\nprint(\"\")\nprint(\"Exercise  2c\\n\")\n\n#Define matrix A and vector b to represent the equation\n\nA = np.array([\n    [5.0, -3.0],\n    [1, -4]\n], dtype=float)\n\nb = np.array((3,-7), dtype=float)\n\n\n#Use the lu-function for the LU-Decomposition\nP,L,U = lu(A)\nprint(\"lower triangular L:\\n\", L)\nprint(\"\\nupper triangular U:\\n\", U)\n\n#Use the lu_factor function to solve the equation with LU-Decomposition\nLU, piv = lu_factor(A)         \nx_lu = lu_solve((LU, piv), b) \nprint(\"\\nsolution for x (LU):\\n\", x_lu)\n\n#Use solve-function\nx_direct = solve(A, b)\nprint(\"\\ndirect solution for x (direkt):\\n\", x_direct)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Exercise 2A\n\nlower triangular L:\n [[1.  0. ]\n [0.2 1. ]]\n\nupper triangular U:\n [[ 5.   3. ]\n [ 0.  -4.6]]\n\nsolution for x (LU):\n [2.34782609 1.08695652]\n\ndirect solution for x (direkt):\n [2.34782609 1.08695652]\n\n\nExercise  2c\n\nlower triangular L:\n [[1.  0. ]\n [0.2 1. ]]\n\nupper triangular U:\n [[ 5.  -3. ]\n [ 0.  -3.4]]\n\nsolution for x (LU):\n [1.94117647 2.23529412]\n\ndirect solution for x (direkt):\n [1.94117647 2.23529412]\n"
        }
      ],
      "execution_count": 166
    },
    {
      "cell_type": "markdown",
      "source": "## Conclusion:\n\nSolving methods reproduce the correct result. \n\n\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Exercise 3 - Velocity dispersion estimation\n\nThe file ``omega_Cen_Sollima2009.txt`` contains a collection of measurements of line-of-sight velocities of stars in the Galactic globular cluster $\\omega$ Cen (NGC 5139). The first column in the file contains the values of the velocities (in km/s), and the second column the values of the associated measurement errors (also in km/s). These data are taken from [Sollima et al. (2009)](https://ui.adsabs.harvard.edu/abs/2009MNRAS.396.2183S/abstract).\n\nWe want to determine the mean velocity $\\bar{v}$ and velocity dispersion $\\sigma$ of these stars, and we do this by using a maximum likelihood estimator, following the procedure described by [Pryor and Meylan (1993)](https://ui.adsabs.harvard.edu/abs/1993ASPC...50..357P/abstract).\n\nWe start by assuming that each velocity measurement $v_i$ ($i = 1,2,...,N$), with associated error $\\delta_{{\\rm v},i}$, is drawn from the normal distribution:\n\n$$ f(v_i) = \\frac{1}{\\sqrt{2 \\pi (\\sigma^2 + \\delta_{{\\rm v},i}^2)}} \\exp\\left[ - \\frac{(v_i - \\bar{v})^2}{2(\\sigma^2 + \\delta_{{\\rm v},i}^2)} \\right] $$ \n\nStandard techniques for forming the likelihood of a set of $N$ velocities and finding its maximum lead to the following two equations:\n\n$$\\sum_{i = 1}^{N}  \\frac{v_i}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)} - \\bar{v} \\sum_{i = 1}^{N}  \\frac{1}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)} = 0$$\n\n$$\\sum_{i = 1}^{N}  \\frac{(v_i - \\bar{v})^2}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)^2} - \\sum_{i = 1}^{N}  \\frac{1}{(\\sigma^2 + \\delta_{{\\rm v},i}^2)} = 0$$\n\nThese equations must be solved numerically to obtain $\\bar{v}$ and $\\sigma$.\n\n**(A)** Discuss what type of problem this is, and list the possible ways (those we have seen in class, of course!) to solve it numerically with built-in python functions.\n\n**(B)** Solve the equations above to obtain the values of the mean velocity $\\bar{v}$ and velocity dispersion $\\sigma$. To do this, use **all** the python built-in functions we discussed in class, and compare the results you obtain. Print out the solutions you get, and verify that they are indeed solutions of the above equations.\n\n**(C)** Explore the input and output of the python built-in functions. Pay particular attention to the values you provide as initial guesses to compute the solution: which values break the algorithm? Which algorithm appears to be more stable?",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    }
  ]
}